{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1THDrfH2ggqCVnBlzucUaMIxNmS9oty-K","timestamp":1680325923713}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5w7f0gwXU7Br","executionInfo":{"status":"ok","timestamp":1682835157296,"user_tz":-330,"elapsed":7688,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}},"outputId":"4a254078-385c-4948-b591-075777e7fa99"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"]}],"source":["import nltk\n","from nltk.corpus import brown\n","#from nltk.tokenize import word_tokenize\n","import numpy as np\n","#import pandas as pd\n","import re\n","import copy\n","#import numpy as np\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","import random #for shuffling list\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import gensim\n","\n","nltk.download('punkt')\n","nltk.download('brown')\n","nltk.download('universal_tagset')\n","dataset = brown.tagged_sents(tagset='universal')"]},{"cell_type":"code","source":["import gensim.downloader as api\n","import json\n","info = api.info()\n","#print(json.dumps(info, indent=4))\n","print(api.load('word2vec-google-news-300', return_path=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8S-AaLMU_Fx","outputId":"96ec7f9e-cb58-46b6-86d8-822d694f7f69","executionInfo":{"status":"ok","timestamp":1682835546819,"user_tz":-330,"elapsed":389528,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 1662.8/1662.8MB downloaded\n","/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n"]}]},{"cell_type":"code","source":["w2v_model = gensim.models.KeyedVectors.load_word2vec_format('/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', binary=True)"],"metadata":{"id":"3_E9sxkSVA2N","executionInfo":{"status":"ok","timestamp":1682835595364,"user_tz":-330,"elapsed":48551,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import torch\n","# Ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"2zm89jRXVCvt","executionInfo":{"status":"ok","timestamp":1682835599358,"user_tz":-330,"elapsed":4003,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["words=[]\n","tags=[]\n","for sent_id in range(len(dataset)):\n","    words_list=[]\n","    tags_list=[]\n","    for i in range(len(dataset[sent_id])):\n","        words_list.append(dataset[sent_id][i][0])\n","        tags_list.append(dataset[sent_id][i][1])\n","    words.append(words_list)\n","    tags.append(tags_list)\n","\n","train_words,test_words, train_tags, test_tags=train_test_split(words,tags,test_size=0.2,train_size=0.8)\n","\n","words_in_corpus = []\n","tags_in_corpus = []\n","\n","for words_list in train_words:\n","    for item in words_list:\n","        words_in_corpus.append(item)\n","for tags_list in train_tags:\n","    for item in tags_list:\n","        tags_in_corpus.append(item)\n","\n","words_in_corpus = list(set(words_in_corpus))\n","tags_in_corpus = list(set(tags_in_corpus))\n","\n","words_in_corpus.sort()\n","tags_in_corpus.sort()\n","\n","print(len(words_in_corpus))\n","print(tags_in_corpus)\n","\n","word_dictionary = dict()\n","tag_dictionary = dict()\n","\n","for i in range ( len(tags_in_corpus) ):\n","    tag_dictionary[tags_in_corpus[i]] = i # 0 based indexing of IDs\n","\n","for i in range ( len(words_in_corpus) ):\n","    word_dictionary[words_in_corpus[i]] = i # 0 based indexing of IDs\n","\n","index_for_word_not_in_corpus = len(words_in_corpus)"],"metadata":{"id":"2ONKVtaFt_35","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682835609987,"user_tz":-330,"elapsed":10635,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}},"outputId":"cf06a365-c977-4498-e051-80db0c02ade8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["50646\n","['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"XGxRENraTC1B","executionInfo":{"status":"ok","timestamp":1682835609990,"user_tz":-330,"elapsed":24,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from torch.nn.utils.rnn import pad_sequence\n","class dataset_pos_ED(Dataset):\n","\n","    def __init__(self,words,tags,device):\n","        \n","        self.words=words\n","        self.tags=tags\n","        self.device=device\n","\n","    def __len__(self):\n","        return len(self.words)\n","    \n","\n","    def feature_matrix(self,words):\n","        f_mat=[]\n","        for i in words:\n","            try:\n","                f_mat.append(torch.Tensor(w2v_model[i]).unsqueeze(dim=0))\n","\n","            except:\n","\n","                x=np.random.normal(loc=0.0,scale=0.1,size=300)\n","                f_mat.append(torch.Tensor(x).unsqueeze(dim=0))\n","        f_mat=torch.cat(f_mat,axis=0).to(self.device)\n","        return f_mat\n","\n","    def __getitem__(self, idx):\n","        # sentence=[]\n","        # tag_list=[]\n","        words=self.words[idx]\n","        tags=self.tags[idx]\n","        # tagged_sent=self.data[idx]\n","        # for item in tagged_sent:\n","            # sentence.append(item[0])\n","            # tag_list.append(item[1])\n","        feature=self.feature_matrix(words)\n","        return (feature), torch.Tensor([int(tag_dictionary[i]) for i in tags])"],"metadata":{"id":"l3lAuJtQmp8d","executionInfo":{"status":"ok","timestamp":1682835609992,"user_tz":-330,"elapsed":25,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["data_train=dataset_pos_ED(train_words,train_tags,\"cpu\")\n","def pad_collate(batch):\n","    (xx, yy) = zip(*batch)\n","    x_lens = [len(x) for x in xx]\n","    y_lens = [len(y) for y in yy]\n","\n","    xx_pad = pad_sequence(xx, batch_first=True, padding_value=11)\n","    yy_pad = pad_sequence(yy, batch_first=True, padding_value=11)\n","\n","    return xx_pad, yy_pad\n","dataloader = DataLoader(data_train, batch_size=100,shuffle=True, num_workers=0, collate_fn=pad_collate)\n"],"metadata":{"id":"QlUGkDyQrUjf","executionInfo":{"status":"ok","timestamp":1682835609994,"user_tz":-330,"elapsed":25,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","class encoder(nn.Module):\n","    def __init__(self,hidden_dim=150,layer_dim=1,in_dim=300,out_dim=12,device=\"cuda\"):\n","        super().__init__()\n","        self.hidden_dim=hidden_dim\n","        self.layer_dim=layer_dim\n","        self.in_dim=in_dim\n","        self.out_dim=out_dim\n","        self.device=device\n","        self.rnn1 = nn.RNN(in_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu',bidirectional=True)        \n","        # self.softmax=nn.Softmax(dim=-1).to(device)\n","        # self.lin=nn.Linear(2*hidden_dim,out_dim)\n","\n","    def forward(self,x):\n","        out,hn=self.rnn1(x)\n","        # x=self.lin(out)\n","        # x=self.softmax(x)\n","        return torch.cat((hn[-1],hn[-2]),axis=1)"],"metadata":{"id":"MoMOJH4Ke0fT","executionInfo":{"status":"ok","timestamp":1682835609995,"user_tz":-330,"elapsed":24,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","class decoder(nn.Module):\n","    def __init__(self,hidden_dim=300,layer_dim=1,in_dim=12,out_dim=12,device=\"cuda\"):\n","        super().__init__()\n","        self.hidden_dim=hidden_dim\n","        self.layer_dim=layer_dim\n","        self.in_dim=in_dim\n","        self.out_dim=out_dim\n","        self.device=device\n","        self.rnn1 = nn.RNN(in_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu',bidirectional=True)        \n","        self.softmax=nn.Softmax(dim=-1).to(device)\n","        self.lin=nn.Linear(2*hidden_dim,out_dim)\n","\n","    def forward(self,x,seq_length):\n","        predictions=[]\n","        \n","        for i in range(seq_length):\n","            if i==0:\n","\n","                input=torch.zeros(x.shape[0],1,12)\n","                input[:,:,0]=torch.ones(x.shape[0],1)\n","                \n","                # print(\"input shape\",input.shape)\n","                x=x.unsqueeze(dim=0).expand(2*self.layer_dim,x.shape[0],x.shape[1])\n","                # print(\"x shape\", x.shape)\n","                out,hn=self.rnn1(input,x)\n","                x=hn\n","            else:\n","                input=torch.zeros(x.shape[0],1,12)\n","                input=torch.nn.functional.one_hot(input_item.long(),num_classes=12).to(device).unsqueeze(1).float()\n","                # input[input_item]=1\n","                # print(\"next iter input shape\",input.shape)\n","                # print(\"hn shape\",hn.shape)\n","                out,hn=self.rnn1(input,hn)\n","            a=self.softmax(self.lin(out.squeeze()))\n","            if i==0:\n","                b=a.unsqueeze(1)\n","            else:\n","                b=torch.cat((b,a.unsqueeze(1)),axis=1 )\n","            # print(\"a shape\",a.shape)\n","            predictions.append(a.argmax(1))\n","            input_item=predictions[-1]\n","            # print(\"input_item shape\",input_item.shape)\n","\n","\n","        \n","        # out,hn=self.rnn1(x)\n","        # x=self.lin(out)\n","        # x=self.softmax(x)\n","        return predictions, b"],"metadata":{"id":"tR20HGGPBBz3","executionInfo":{"status":"ok","timestamp":1682835609996,"user_tz":-330,"elapsed":23,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class Model_ED(nn.Module):\n","    def __init__(self,device=\"cuda\"):\n","        super().__init__()\n","        self.encoder=encoder(device=device)\n","        self.decoder=decoder(device=device)\n","    def forward(self,x,seq_length):\n","        x=self.encoder(x)\n","        # print(\"enocder shape\", x.shape)\n","        # print(seq_length)\n","        preds,outs=self.decoder(x,seq_length)\n","        return preds,outs"],"metadata":{"id":"Wu8VGW2dH_cs","executionInfo":{"status":"ok","timestamp":1682835609997,"user_tz":-330,"elapsed":24,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import time\n","device=\"cuda\"\n","# dataloader = DataLoader(data_train, batch_size=100,\n","                        # shuffle=True, num_workers=0)\n","model=Model_ED(device=device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n","loss_fn=nn.CrossEntropyLoss()\n","model.train()\n","prev_end=time.time()\n","num_epochs=10\n","for e in range(num_epochs):\n","    total_loss=0.0\n","    for batch, (X, y) in enumerate(dataloader):\n","        size = len(dataloader.dataset)\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        # print(X.shape)\n","        # print(y.shape)\n","        preds,outs = model(X,X.shape[1])\n","        # print(pred.shape)\n","        # print(y)\n","        y=torch.nn.functional.one_hot(y.long(),num_classes=12).to(device).float()\n","        # print(pred.shape)\n","        # print(y.shape)\n","        loss = loss_fn(outs, y)\n","        total_loss+=loss\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch % 10 == 0:\n","            end=time.time()\n","            loss, current = loss.item(), (batch + 1) * len(X)\n","            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","            print(\"time: \", end-prev_end)\n","            rev_end=end\n","    print(\"Total loss for epoch {}\".format(e+1), total_loss)\n","            "],"metadata":{"id":"Gpd3Kq8T0XDM","colab":{"base_uri":"https://localhost:8080/","height":989},"outputId":"6588f239-6f9b-4b5d-af37-eb2d7dbe933c","executionInfo":{"status":"error","timestamp":1682836496640,"user_tz":-330,"elapsed":16,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":13,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-ecefeeee642b>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# print(X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# print(y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m# print(pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print(y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-7e7d38d0d06b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, seq_length)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# print(\"enocder shape\", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# print(seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-57e5da2c069c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# x=self.lin(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# x=self.softmax(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    511\u001b[0m                                       self.batch_first)\n\u001b[1;32m    512\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m                 result = _VF.rnn_relu(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    514\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m                                       self.batch_first)\n","\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cuda:0 and parameter tensor at cpu"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"huBtSEEM9T0q","executionInfo":{"status":"aborted","timestamp":1682835610861,"user_tz":-330,"elapsed":41,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"outputs":[],"source":["def train_func(data_train, data_test):\n","    import time\n","    device=\"cuda\"\n","    dataloader = DataLoader(data_train, batch_size=100,\n","                            shuffle=True, num_workers=0)\n","    model=encoder(device=device)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n","    loss_fn=nn.CrossEntropyLoss()\n","    model.train()\n","    start=time.time()\n","    num_epochs=1\n","    for e in range(num_epochs):\n","\n","        for batch, (X, y) in enumerate(dataloader):\n","            size = len(dataloader.dataset)\n","            X, y = X.to(device), y.to(device)\n","\n","            # Compute prediction error\n","            pred = model(X)\n","            # print(pred.shape)\n","            # print(y.shape)\n","            loss = loss_fn(pred, y)\n","\n","            # Backpropagation\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            break\n","            if batch % 500 == 0:\n","                end=time.time()\n","                loss, current = loss.item(), (batch + 1) * len(X)\n","                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","                print(\"time: \", end-start)\n","            break\n","        break\n","    \n","    \n","\n","    dataloader = DataLoader(data_test, batch_size=100,\n","                            shuffle=True, num_workers=0)\n","       \n","    a = torch.tensor([]).to(device)\n","    b = torch.tensor([]).to(device)\n","\n","    for batch, (X, y) in enumerate(dataloader):\n","        size = len(dataloader.dataset)\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        # print(pred.shape)\n","        # print(y.shape)\n","        loss = loss_fn(pred, y)\n","        a = torch.cat((a, y))\n","        b = torch.cat((b, torch.argmax(pred, axis = 1)))\n","\n","    return a, b"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UUMBptGXVnvf","executionInfo":{"status":"aborted","timestamp":1682835610864,"user_tz":-330,"elapsed":42,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"outputs":[],"source":["def accuracy_per_fold(train_w, train_t, test_w, test_t):\n","\n","    train_words,train_tags=train_w, train_t\n","    # train_words,test_words, train_tags, test_tags=train_test_split(words,tags,test_size=0.2,train_size=0.8)\n","\n","    words_in_corpus = []\n","    tags_in_corpus = []\n","\n","    for words_list in train_words:\n","        for item in words_list:\n","            words_in_corpus.append(item)\n","    for tags_list in train_tags:\n","        for item in tags_list:\n","            tags_in_corpus.append(item)\n","\n","    words_in_corpus = list(set(words_in_corpus))\n","    tags_in_corpus = list(set(tags_in_corpus))\n","\n","    words_in_corpus.sort()\n","    tags_in_corpus.sort()\n","\n","    print(len(words_in_corpus))\n","    print(tags_in_corpus)\n","\n","    word_dictionary = dict()\n","    tag_dictionary = dict()\n","\n","    for i in range ( len(tags_in_corpus) ):\n","        tag_dictionary[tags_in_corpus[i]] = i # 0 based indexing of IDs\n","\n","    for i in range ( len(words_in_corpus) ):\n","        word_dictionary[words_in_corpus[i]] = i # 0 based indexing of IDs\n","\n","    index_for_word_not_in_corpus = len(words_in_corpus)\n","\n","\n","\n","    data_train = dataset_pos_ED(train_w,train_t,\"cuda\")\n","    data_test = dataset_pos_ED(test_w,test_t,\"cuda\")\n","    test_y,predictions = train_func(data_train, data_test)\n","    \n","    f1 = 0\n","    prec = 0\n","    recall = 0\n","    \n","\n","    #for i in range( len(actual_tags) ):\n","    #    f1 += f1_score(actual_tags[i], predicted_tags[i], average='weighted')\n","    #    prec += precision_score(actual_tags[i], predicted_tags[i], average='weighted')\n","    #    recall += recall_score(actual_tags[i], predicted_tags[i], average='weighted')\n","    per_pos=[[] for i in range(12)]\n","    #per_pos_act=[[] for i in range(0,12)]\n","    for i in range(len(test_y)):\n","        per_pos[test_y[i].to(torch.int64).item()].append(predictions[i].to(torch.int64).item())\n","    print(\"my_fold------------------------\")\n","    for i in range(len(per_pos)):\n","        print(i,\"-----\")\n","        true_tag=[i for j in range(len(per_pos[i]))]\n","        print(\"precision\",precision_score(per_pos[i],true_tag, average='weighted'))\n","        print(\"recall\",recall_score(per_pos[i],true_tag, average='weighted'))\n","        print(\"f1\",f1_score(per_pos[i],true_tag, average='weighted'))\n","    print(\"overall for the batch:\")\n","    precision=precision_score(test_y.to('cpu'),predictions.to('cpu'), average='weighted')\n","    recall=recall_score(test_y.to('cpu'),predictions.to('cpu'), average='weighted')\n","    f1=f1_score(test_y.to('cpu'),predictions.to('cpu'), average='weighted')\n","    print(\"precision\",precision)\n","    print(\"recall\",recall)\n","    print(\"f1\",f1)\n","\n","        \n","    return [precision, recall, f1]\n","    #return [f1/len(actual_tags), prec/len(actual_tags), recall/len(actual_tags)]\n","\n","#total_acc_for_split1 = accuracy_per_fold(all_sentences[:57000], all_sentences[56000:56010])\n","#total_acc_for_split2 = accuracy_per_fold(all_sentences[:57000], all_sentences[57000:57010])\n","\n","#print(\"\\nTotal accuracy for the above split1: \" + str(total_acc_for_split1))\n","#print(\"Total accuracy for the above split2: \" + str(total_acc_for_split2) + \"\\n\")\n","#exit(0)\n","\n","def cross_validation_accuracy(words, tags):\n","    all_accuracies = []\n","    total_acc = [0, 0, 0]\n","\n","    num_sentences = len(words)\n","\n","    fold_size = int(num_sentences / 5)\n","\n","    print(fold_size)\n","\n","    fold1_train_w=words[:4*fold_size]\n","    fold1_test_w=words[4*fold_size:]\n","    fold2_train_w=words[:3*fold_size]+words[4*fold_size:]\n","    fold2_test_w=words[3*fold_size:4*fold_size]\n","    fold3_train_w=words[:2*fold_size]+words[3*fold_size:]\n","    fold3_test_w=words[2*fold_size:3*fold_size]\n","    fold4_train_w=words[:1*fold_size]+words[2*fold_size:]\n","    fold4_test_w=words[1*fold_size:2*fold_size]\n","    fold5_train_w=words[1*fold_size:]\n","    fold5_test_w=words[:1*fold_size]\n","\n","    fold1_train_t=tags[:4*fold_size]\n","    fold1_test_t=tags[4*fold_size:]\n","    fold2_train_t=tags[:3*fold_size]+tags[4*fold_size:]\n","    fold2_test_t=tags[3*fold_size:4*fold_size]\n","    fold3_train_t=tags[:2*fold_size]+tags[3*fold_size:]\n","    fold3_test_t=tags[2*fold_size:3*fold_size]\n","    fold4_train_t=tags[:1*fold_size]+tags[2*fold_size:]\n","    fold4_test_t=tags[1*fold_size:2*fold_size]\n","    fold5_train_t=tags[1*fold_size:]\n","    fold5_test_t=tags[:1*fold_size]\n","\n","    all_accuracies.append(accuracy_per_fold(fold1_train_w,fold1_train_t, fold1_test_w, fold1_test_t))\n","    print(\"Accuracy for fold \", \"1\", \" is : \", str(all_accuracies[0]))\n","    total_acc[0] += all_accuracies[0][0]\n","    total_acc[1] += all_accuracies[0][1]\n","    total_acc[2] += all_accuracies[0][2]\n","\n","\n","    all_accuracies.append(accuracy_per_fold(fold2_train_w,fold2_train_t, fold2_test_w, fold2_test_t))\n","    print(\"Accuracy for fold \", \"2\", \" is : \", str(all_accuracies[1]))\n","    total_acc[0] += all_accuracies[1][0]\n","    total_acc[1] += all_accuracies[1][1]\n","    total_acc[2] += all_accuracies[1][2]\n","\n","    all_accuracies.append(accuracy_per_fold(fold3_train_w,fold3_train_t, fold3_test_w, fold3_test_t))\n","    print(\"Accuracy for fold \", \"3\", \" is : \", str(all_accuracies[2]))\n","    total_acc[0] += all_accuracies[2][0]\n","    total_acc[1] += all_accuracies[2][1]\n","    total_acc[2] += all_accuracies[2][2]\n","\n","    all_accuracies.append(accuracy_per_fold(fold4_train_w,fold4_train_t, fold4_test_w, fold4_test_t))\n","    print(\"Accuracy for fold \", \"4\", \" is : \", str(all_accuracies[3]))\n","    total_acc[0] += all_accuracies[3][0]\n","    total_acc[1] += all_accuracies[3][1]\n","    total_acc[2] += all_accuracies[3][2]\n","\n","    all_accuracies.append(accuracy_per_fold(fold5_train_w,fold5_train_t, fold5_test_w, fold5_test_t))\n","    print(\"Accuracy for fold \", \"5\", \" is : \", str(all_accuracies[4]))\n","    total_acc[0] += all_accuracies[4][0]\n","    total_acc[1] += all_accuracies[4][1]\n","    total_acc[2] += all_accuracies[4][2]\n","\n","    print(\"Cross validation accuracy is : \", str(np.array(total_acc) / 5))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axWeCjvCAeC0","executionInfo":{"status":"aborted","timestamp":1682835610866,"user_tz":-330,"elapsed":43,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"outputs":[],"source":["cross_validation_accuracy(train_words, train_tags)"]},{"cell_type":"code","source":[],"metadata":{"id":"1gHbbNXSfSF6","executionInfo":{"status":"aborted","timestamp":1682835610869,"user_tz":-330,"elapsed":45,"user":{"displayName":"Adit Akarsh","userId":"09670249152159733364"}}},"execution_count":null,"outputs":[]}]}